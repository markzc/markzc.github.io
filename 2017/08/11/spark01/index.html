<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="spark," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="介绍
Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。



四种运行模式：local(多用于测试)，standalone，Mesos,YARN

一切都以RDD为基础(Resilient D">
<meta property="og:type" content="article">
<meta property="og:title" content="spark第一阶段">
<meta property="og:url" content="https://zhangchong.github.io/2017/08/11/spark01/index.html">
<meta property="og:site_name" content="张冲的BLOG">
<meta property="og:description" content="介绍
Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。



四种运行模式：local(多用于测试)，standalone，Mesos,YARN

一切都以RDD为基础(Resilient D">
<meta property="og:image" content="https://zhangchong.github.io/uploads/spark/spark01/22.jpg">
<meta property="og:image" content="https://zhangchong.github.io/uploads/spark/spark01/11.jpg">
<meta property="og:updated_time" content="2017-09-28T02:35:49.638Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spark第一阶段">
<meta name="twitter:description" content="介绍
Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。



四种运行模式：local(多用于测试)，standalone，Mesos,YARN

一切都以RDD为基础(Resilient D">
<meta name="twitter:image" content="https://zhangchong.github.io/uploads/spark/spark01/22.jpg">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 'undefined',
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="https://zhangchong.github.io/2017/08/11/spark01/"/>


  <title> spark第一阶段 | 张冲的BLOG </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">张冲的BLOG</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup">
 <span class="search-icon fa fa-search"></span>
 <input type="text" id="local-search-input">
 <div id="local-search-result"></div>
 <span class="popup-btn-close">close</span>
</div>


    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                spark第一阶段
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-08-11T16:18:56+08:00" content="2017-08-11">
              2017-08-11
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/08/11/spark01/" class="leancloud_visitors" data-flag-title="spark第一阶段">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><blockquote>
<p>Spark 是一种与 Hadoop 相似的开源集群计算环境，但是两者之间还存在一些不同之处，这些有用的不同之处使 Spark 在某些工作负载方面表现得更加优越，换句话说，Spark 启用了内存分布数据集，除了能够提供交互式查询外，它还可以优化迭代工作负载。</p>
</blockquote>
<p><img src="/uploads/spark/spark01/22.jpg" alt=""></p>
<ul>
<li><p>四种运行模式：local(多用于测试)，standalone，Mesos,YARN</p>
</li>
<li><p>一切都以RDD为基础(Resilient Distributed Dataset):弹性的分布式数据集</p>
<ul>
<li>一列分片</li>
<li>每一个分片上都会有函数</li>
<li>一系列的依赖</li>
<li>对key-value的RDD可以指定一个分片器</li>
<li>指定运算在哪台机器上</li>
</ul>
</li>
<li><p>容错：每个RDD都会记录自己依赖于哪个RDD，万一某个RDD的某些partition挂了，可以通过其它RDD并行计算迅速恢复出来。</p>
</li>
</ul>
<p><img src="/uploads/spark/spark01/11.jpg" alt=""></p>
<ul>
<li><p>集群配置:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">spark_env.sh</div><div class="line">  export JAVA_HOME=</div><div class="line">  export SPARK_MASTER_IP=</div><div class="line">  export SPARK_WORKER_CORES=</div><div class="line">  export SPARK_WORKER_INSTANCES =</div><div class="line">  export SPARK_WORKER_MEMORY=</div><div class="line">  export SPARK_MASTER_PORT=</div><div class="line">  export SPARK_JAVA_OPTS=&quot;-verbose:gc -XX:-PrintGCDetails -XX:+PrintGCTimeStamps&quot;</div><div class="line"> </div><div class="line">salves</div><div class="line">  xx.xx.xx.2</div><div class="line">  xx.xx.xx.3</div><div class="line">  xx.xx.xx.4</div><div class="line">  xx.xx.xx.5</div></pre></td></tr></table></figure>
</li>
<li><p>配置好之后启动的时候，用<code>MASTER=spark://host:port ./spark-shell</code>  因为在0.9.0之前有一些错误，所以需要指定master要不然可能会是<code>standalone</code>模式启动。</p>
</li>
<li><p>可以指定启动时候的内存，可以直接在启动脚本上设置<code>export  SPARK_MEM=25g</code></p>
</li>
<li><p>在集群上运行spark的jar包<code>java -jar 运行的jar 依赖的jar 要取出来的数据位置  放到的位置</code></p>
</li>
</ul>
<h3 id="RDDs"><a href="#RDDs" class="headerlink" title="RDDs"></a>RDDs</h3><blockquote>
<p>弹性分布式数据集（RDDs）。 Spark 核心的概念是 Resilient Distributed Dataset (RDD)：一个可并行操作的有容错机制的数据集合。有 2 种方式创建 RDDs：第一种是在你的驱动程序中并行化一个已经存在的集合；另外一种是引用一个外部存储系统的数据集，例如共享的文件系统，HDFS，HBase或其他 Hadoop 数据格式的数据源。</p>
</blockquote>
<h4 id="并行集合"><a href="#并行集合" class="headerlink" title="并行集合"></a>并行集合</h4><ul>
<li>并行集合 (Parallelized collections) 的创建是通过在一个已有的集合(Scala Seq)上调用 SparkContext 的 parallelize 方法实现的。集合中的元素被复制到一个可并行操作的分布式数据集中。例如，这里演示了如何在一个包含 1 到 5 的数组中创建并行集合：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">val data = Array(1, 2, 3, 4, 5) </div><div class="line">val distData = sc.parallelize(data)</div></pre></td></tr></table></figure>
<ul>
<li><p>一旦创建完成，这个分布式数据集<code>(distData)</code>就可以被并行操作。例如，我们可以调用 <code>distData.reduce((a, b) =&gt; a + b)</code> 将这个数组中的元素相加。我们以后再描述在分布式上的一些操作。</p>
</li>
<li><p>并行集合一个很重要的参数是切片数<code>(slices)</code>，表示一个数据集切分的份数。Spark 会在集群上为每一个切片运行一个任务。你可以在集群上为每个 CPU 设置 2-4 个切片<code>(slices)</code>。正常情况下，Spark 会试着基于你的集群状况自动地设置切片的数目。然而，你也可以通过 <code>parallelize</code> 的第二个参数手动地设置(例如：<code>sc.parallelize(data, 10)</code>)。</p>
</li>
</ul>
<h4 id="外部数据集"><a href="#外部数据集" class="headerlink" title="外部数据集"></a>外部数据集</h4><blockquote>
<p>Spark 可以从任何一个 Hadoop 支持的存储源创建分布式数据集，包括你的本地文件系统，HDFS，Cassandra，HBase，Amazon S3等。 Spark 支持文本文件(text files)，SequenceFiles 和其他 Hadoop InputFormat。</p>
</blockquote>
<ul>
<li>文本文件 RDDs 可以使用 SparkContext 的 textFile 方法创建。 在这个方法里传入文件的 URI (机器上的本地路径或 hdfs://，s3n:// 等)，然后它会将文件读取成一个行集合。这里是一个调用例子：</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">scala&gt; val distFile = sc.textFile(&quot;data.txt&quot;) </div><div class="line">distFile: RDD[String] = MappedRDD@1d4cee08</div></pre></td></tr></table></figure>
<ul>
<li><p>一旦创建完成，distFiile 就能做数据集操作。例如，我们可以用下面的方式使用 map 和 reduce 操作将所有行的长度相加：distFile.map(s =&gt; s.length).reduce((a, b) =&gt; a + b)。</p>
</li>
<li><p>注意，Spark 读文件时：</p>
<ul>
<li><p>如果使用本地文件系统路径，文件必须能在 work 节点上用相同的路径访问到。要么复制文件到所有的 workers，要么使用网络的方式共享文件系统。</p>
</li>
<li><p>所有 Spark 的基于文件的方法，包括 textFile，能很好地支持文件目录，压缩过的文件和通配符。例如，你可以使用 textFile(“/my/文件目录”)，textFile(“/my/文件目录/<em>.txt”) 和 textFile(“/my/文件目录/</em>.gz”)。</p>
</li>
<li><p>textFile 方法也可以选择第二个可选参数来控制切片(slices)的数目。默认情况下，Spark 为每一个文件块(HDFS 默认文件块大小是 64M)创建一个切片(slice)。但是你也可以通过一个更大的值来设置一个更高的切片数目。注意，你不能设置一个小于文件块数目的切片值。</p>
</li>
</ul>
</li>
<li><p>除了文本文件，Spark 的 Scala API 支持其他几种数据格式：</p>
<ul>
<li><p>SparkContext.wholeTextFiles 让你读取一个包含多个小文本文件的文件目录并且返回每一个(filename, content)对。与 textFile 的差异是：它记录的是每个文件中的每一行。</p>
</li>
<li><p>对于 SequenceFiles，可以使用 SparkContext 的 sequenceFile[K, V] 方法创建，K 和 V 分别对应的是 key 和 values 的类型。像 IntWritable 与 Text 一样，它们必须是 Hadoop 的 Writable 接口的子类。另外，对于几种通用的 Writables，Spark 允许你指定原生类型来替代。例如： sequenceFile[Int, String] 将会自动读取 IntWritables 和 Text。</p>
</li>
<li><p>对于其他的 Hadoop InputFormats，你可以使用 SparkContext.hadoopRDD 方法，它可以指定任意的 JobConf，输入格式(InputFormat)，key 类型，values 类型。你可以跟设置 Hadoop job 一样的方法设置输入源。你还可以在新的 MapReduce 接口(org.apache.hadoop.mapreduce)基础上使用 SparkContext.newAPIHadoopRDD(译者注：老的接口是 SparkContext.newHadoopRDD)。</p>
</li>
<li><p>RDD.saveAsObjectFile 和 SparkContext.objectFile 支持保存一个RDD，保存格式是一个简单的 Java 对象序列化格式。这是一种效率不高的专有格式，如 Avro，它提供了简单的方法来保存任何一个 RDD。</p>
</li>
</ul>
</li>
</ul>
<h4 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h4><blockquote>
<p>RDDs 支持 2 种类型的操作：转换(transformations) 从已经存在的数据集中创建一个新的数据集；动作(actions) 在数据集上进行计算之后返回一个值到驱动程序。例如，map 是一个转换操作，它将每一个数据集元素传递给一个函数并且返回一个新的 RDD。另一方面，reduce 是一个动作，它使用相同的函数来聚合 RDD 的所有元素，并且将最终的结果返回到驱动程序(不过也有一个并行 reduceByKey 能返回一个分布式数据集)。</p>
</blockquote>
<ul>
<li><p>在 Spark 中，所有的转换(transformations)都是惰性(lazy)的，它们不会马上计算它们的结果。相反的，它们仅仅记录转换操作是应用到哪些基础数据集(例如一个文件)上的。转换仅仅在这个时候计算：当动作(action) 需要一个结果返回给驱动程序的时候。这个设计能够让 Spark 运行得更加高效。例如，我们可以实现：通过 map 创建一个新数据集在 reduce 中使用，并且仅仅返回 reduce 的结果给 driver，而不是整个大的映射过的数据集。</p>
</li>
<li><p>默认情况下，每一个转换过的 RDD 会在每次执行动作(action)的时候重新计算一次。然而，你也可以使用 persist (或 cache)方法持久化(persist)一个 RDD 到内存中。在这个情况下，Spark 会在集群上保存相关的元素，在你下次查询的时候会变得更快。在这里也同样支持持久化 RDD 到磁盘，或在多个节点间复制。</p>
</li>
<li><p>为了说明 RDD 基本知识，考虑下面的简单程序：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">val lines = sc.textFile(&quot;data.txt&quot;) </div><div class="line">val lineLengths = lines.map(s =&gt; s.length) </div><div class="line">val totalLength = lineLengths.reduce((a, b) =&gt; a + b)</div></pre></td></tr></table></figure>
</li>
<li><p>第一行是定义来自于外部文件的 RDD。这个数据集并没有加载到内存或做其他的操作：lines 仅仅是一个指向文件的指针。第二行是定义 lineLengths，它是 map 转换(transformation)的结果。同样，lineLengths 由于懒惰模式也没有立即计算。最后，我们执行 reduce，它是一个动作(action)。在这个地方，Spark 把计算分成多个任务(task)，并且让它们运行在多个机器上。每台机器都运行自己的 map 部分和本地 reduce 部分。然后仅仅将结果返回给驱动程序。</p>
</li>
<li><p>如果我们想要再次使用 lineLengths，我们可以添加：<code>lineLengths.persist()</code>,在 reduce 之前，它会导致 lineLengths 在第一次计算完成之后保存到内存中。</p>
</li>
</ul>
<h4 id="使用键值对"><a href="#使用键值对" class="headerlink" title="使用键值对"></a>使用键值对</h4><ul>
<li><p>虽然很多 Spark 操作工作在包含任意类型对象的 RDDs 上的，但是少数几个特殊操作仅仅在键值(key-value)对 RDDs 上可用。最常见的是分布式 “shuffle” 操作，例如根据一个 key 对一组数据进行分组和聚合。</p>
</li>
<li><p>在 Scala 中，这些操作在包含二元组(Tuple2)(在语言的内建元组中，通过简单的写 (a, b) 创建) 的 RDD 上自动地变成可用的，只要在你的程序中导入 org.apache.spark.SparkContext._ 来启用 Spark 的隐式转换。在 PairRDDFunctions 的类里键值对操作是可以使用的，如果你导入隐式转换它会自动地包装成元组 RDD。</p>
</li>
<li><p>例如，下面的代码在键值对上使用 reduceByKey 操作来统计在一个文件里每一行文本内容出现的次数：</p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">val lines = sc.textFile(&quot;data.txt&quot;) </div><div class="line">val pairs = lines.map(s =&gt; (s, 1)) </div><div class="line">val counts = pairs.reduceByKey((a, b) =&gt; a + b)</div></pre></td></tr></table></figure>
<ul>
<li><p>我们也可以使用 counts.sortByKey()，例如，将键值对按照字母进行排序，最后 counts.collect() 把它们作为一个对象数组带回到驱动程序。</p>
</li>
<li><p>注意：当使用一个自定义对象作为 key 在使用键值对操作的时候，你需要确保自定义 equals() 方法和 hashCode() 方法是匹配的。</p>
</li>
</ul>
<h4 id="Transformations"><a href="#Transformations" class="headerlink" title="Transformations"></a>Transformations</h4><blockquote>
<p>下面的表格列了 Spark 支持的一些常用 transformations。</p>
</blockquote>
<table>
<thead>
<tr>
<th>Transformation</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>map(func)</td>
<td>返回一个新的分布式数据集，将数据源的每一个元素传递给函数func映射组成。</td>
</tr>
<tr>
<td>filter(func)</td>
<td>返回一个新的数据集，从数据源中选中一些元素通过函数 func 返回true。</td>
</tr>
<tr>
<td>flatMap(func)</td>
<td>类似于 map，但是每个输入项能被映射成多个输出项(所以 func必须返回一个 Seq，而不是单个 item)。</td>
</tr>
<tr>
<td>mapPartitions(func)</td>
<td>类似于 map，但是分别运行在 RDD 的每个分区上，所以 func的类型必须是 Iterator<t> =&gt; Iterator<u> 当运行在类型为 T 的 RDD 上。</u></t></td>
</tr>
<tr>
<td>mapPartitionsWithIndex(func)</td>
<td>类似于 mapPartitions，但是 func 需要提供一个 integer 值描述索引(index)，所以 func 的类型必须是 (Int, Iterator) =&gt; Iterator当运行在类型为 T 的 RDD 上。</td>
</tr>
<tr>
<td>sample(withReplacement, fraction, seed)</td>
<td>对数据进行采样。</td>
</tr>
<tr>
<td>union(otherDataset)</td>
<td>返回一个包含源数据集和参数中元素的并集的新数据集。</td>
</tr>
<tr>
<td>intersection(otherDataset)</td>
<td>返回包含源数据集和参数中的元素的新RDD。</td>
</tr>
<tr>
<td>distinct([numTasks]))</td>
<td>返回一个包含源数据集的不同元素的新数据集。</td>
</tr>
<tr>
<td>groupByKey([numTasks])</td>
<td>当对（K，V）对的数据集进行调用时，返回（K，Iterable）的数据集。注意：如果要分组以便在每个键上执行聚合（例如总和或平均值），则使用reduceByKey或combineByKey将产生更好的性能。注意：默认情况下，输出中的并行级别取决于父RDD的分区数。您可以传递一个可选的numTasks参数来设置不同数量的任务。</td>
</tr>
<tr>
<td>reduceByKey(func, [numTasks])</td>
<td>当对（K，V）对的数据集进行调用时，返回（K，V对的数据集，其中使用给定的reduce函数func聚合每个键的值，该函数必须是类型（V，V）=&gt; V.像groupByKey一样，可以通过可选的第二个参数来配置reduce任务的数量。</td>
</tr>
<tr>
<td>aggregateByKey(zeroValue)(seqOp, combOp, [numTasks])</td>
<td>当（K，V）对的数据集被调用时，返回一个数据集（K，U）对，其中使用给定的组合函数和中性的“零”值对每个键的值进行聚合。允许不同于输入值类型的聚合值类型，同时避免不必要的分配。像groupByKey一样，reduce任务的数量可以通过可选的第二个参数进行配置。</td>
</tr>
<tr>
<td>sortByKey([ascending], [numTasks])</td>
<td>在K实现有序的（K，V）对的数据集上被调用时，按照布尔升序参数中指定的按升序或降序的顺序返回按键排序的（K，V）对的数据集。</td>
</tr>
<tr>
<td>join(otherDataset, [numTasks])</td>
<td>当对类型（K，V）和（K，W）的数据集进行调用时，返回一个（K，（V，W））对的数据集与每个键的所有元素对。还通过leftOuterJoin和rightOuterJoin支持外连接。</td>
</tr>
<tr>
<td>cogroup(otherDataset, [numTasks])</td>
<td>当调用类型（K，V）和（K，W）的数据集时，返回一个数据集（K，Iterable，Iterable元组。这个操作也叫做GroupWith。</td>
</tr>
<tr>
<td>cartesian(otherDataset)</td>
<td>当对类型T和U的数据集进行调用时，返回（T，U）对（所有元素对）的数据集。</td>
</tr>
<tr>
<td>pipe(command, [envVars])</td>
<td>通过shell命令管理RDD的每个分区，例如一个Perl或bash脚本。RDD元素被写入到进程的stdin中，并且将其输出的行输出返回为字符串的RDD。</td>
</tr>
<tr>
<td>coalesce(numPartitions)</td>
<td>将RDD中的分区数减少到numPartition。过滤大型数据集后，对于运行操作更有效。</td>
</tr>
<tr>
<td>repartition(numPartitions)</td>
<td>随机重新清理RDD中的数据以创建更多或更少的分区，并在其间平衡。这总是通过网络洗牌所有的数据。</td>
</tr>
</tbody>
</table>
<h4 id="Actions"><a href="#Actions" class="headerlink" title="Actions"></a>Actions</h4><blockquote>
<p>下面的表格列了 Spark 支持的一些常用 actions。</p>
</blockquote>
<table>
<thead>
<tr>
<th>Action</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td>reduce(func)</td>
<td>Aggregate the elements of the dataset using a function func (which takes two arguments and returns one). The function should be commutative and associative so that it can be computed correctly in parallel.</td>
</tr>
<tr>
<td>collect()</td>
<td>Return all the elements of the dataset as an array at the driver program. This is usually useful after a filter or other operation that returns a sufficiently small subset of the data.</td>
</tr>
<tr>
<td>count()</td>
<td>Return the number of elements in the dataset.</td>
</tr>
<tr>
<td>first()</td>
<td>Return the first element of the dataset (similar to take(1)).</td>
</tr>
<tr>
<td>take(n)</td>
<td>Return an array with the first n elements of the dataset. Note that this is currently not executed in parallel. Instead, the driver program computes all the elements.</td>
</tr>
<tr>
<td>takeSample(withReplacement, num, [seed])</td>
<td>Return an array with a random sample of num elements of the dataset, with or without replacement, optionally pre-specifying a random number generator seed.</td>
</tr>
<tr>
<td>takeOrdered(n, [ordering])</td>
<td>Return the first n elements of the RDD using either their natural order or a custom comparator.</td>
</tr>
<tr>
<td>saveAsTextFile(path)</td>
<td>Write the elements of the dataset as a text file (or set of text files) in a given directory in the local filesystem, HDFS or any other Hadoop-supported file system. Spark will call toString on each element to convert it to a line of text in the file.</td>
</tr>
<tr>
<td>saveAsSequenceFile(path) (Java and Scala)</td>
<td>Write the elements of the dataset as a Hadoop SequenceFile in a given path in the local filesystem, HDFS or any other Hadoop-supported file system. This is available on RDDs of key-value pairs that either implement Hadoop’s Writable interface. In Scala, it is also available on types that are implicitly convertible to Writable (Spark includes conversions for basic types like Int, Double, String, etc).</td>
</tr>
<tr>
<td>saveAsObjectFile(path) (Java and Scala)</td>
<td>Write the elements of the dataset in a simple format using Java serialization, which can then be loaded using SparkContext.objectFile().</td>
</tr>
<tr>
<td>countByKey()</td>
<td>Only available on RDDs of type (K, V). Returns a hashmap of (K, Int) pairs with the count of each key.</td>
</tr>
<tr>
<td>foreach(func)</td>
<td>Run a function func on each element of the dataset. This is usually done for side effects such as updating an accumulator variable (see below) or interacting with external storage systems.</td>
</tr>
</tbody>
</table>
<h2 id="SparkStreaming"><a href="#SparkStreaming" class="headerlink" title="SparkStreaming"></a>SparkStreaming</h2><p>SparkStreaming 是一个流式处理框架，处理的模式是微批处理（微批有多大？通过时间来设置这个批有多大[For example :batch Interval 5s]）<br>SparkStreaming 基于DStream(Discretized Streams:离散的数据流)来进行编程，处理的是一个流，这个流什么时候切成一个rdd–&gt;根据batchinterval 来决定何时切割成一个RDD。</p>

      
    </div>

    <div>
      
        
<div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/uploads/wechat-qcode.jpg" alt="张冲 wechat" style="width: 200px; max-width: 100%;"/>
    <div>欢迎扫一扫上面的微信关注我，一起交流！</div>
</div>


      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>坚持原创技术分享，您的支持将鼓励我继续创，点击打赏！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/uploads/wechat-pay.PNG" alt="张冲 WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/uploads/zhifubao-pay.PNG" alt="张冲 Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag">#spark</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/08/06/hadoop05/" rel="next" title="hadoop第五阶段">
                <i class="fa fa-chevron-left"></i> hadoop第五阶段
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/08/20/spark02/" rel="prev" title="spark第二阶段">
                spark第二阶段 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>

   <div>
  
    <div>
    
<!-- 来必力City版安装代码 -->
<div id="lv-container" data-id="city" data-uid="MTAyMC8yOTc2My82MzI5">
	<script type="text/javascript">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];

       if (typeof LivereTower === 'function') { return; }

       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;

       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
<noscript> 为正常使用来必力评论功能请激活JavaScript</noscript>
</div>
<!-- City版安装代码已完成 -->

</div>
  
</div>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/1.jpg"
               alt="张冲" />
          <p class="site-author-name" itemprop="name">张冲</p>
          <p class="site-description motion-element" itemprop="description">Life was like a box of chocolates, you never know what you’re gonna get.</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">48</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">27</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/zhangchong" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://weibo.com/3490969043" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://blog.csdn.net/john_zc" target="_blank" title="CSDN">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  CSDN
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:zc2457@126.com" target="_blank" title="Email：zc2457@126.com">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  Email：zc2457@126.com
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              友情链接
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.toutiao.com/c/user/2753468180/#mid=1561902103771137" title="推荐《洵视天下》的主页" target="_blank">推荐《洵视天下》的主页</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="https://#" title="这里有很多位置等着你" target="_blank">这里有很多位置等着你</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#介绍"><span class="nav-number">1.</span> <span class="nav-text">介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#RDDs"><span class="nav-number">1.1.</span> <span class="nav-text">RDDs</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#并行集合"><span class="nav-number">1.1.1.</span> <span class="nav-text">并行集合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#外部数据集"><span class="nav-number">1.1.2.</span> <span class="nav-text">外部数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#RDD操作"><span class="nav-number">1.1.3.</span> <span class="nav-text">RDD操作</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用键值对"><span class="nav-number">1.1.4.</span> <span class="nav-text">使用键值对</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Transformations"><span class="nav-number">1.1.5.</span> <span class="nav-text">Transformations</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Actions"><span class="nav-number">1.1.6.</span> <span class="nav-text">Actions</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SparkStreaming"><span class="nav-number">2.</span> <span class="nav-text">SparkStreaming</span></a></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张冲</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  




  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = decodeURIComponent(data.url);
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("22dObQGNrAe90ze3Kbtmu5hG-gzGzoHsz", "0j5eGtmDLCCURrOtIpv1gw2X");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  


</body>
</html>
